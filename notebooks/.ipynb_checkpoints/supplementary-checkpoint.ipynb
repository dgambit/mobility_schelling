{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fbe243",
   "metadata": {},
   "source": [
    "# Supplementary figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcd2a2",
   "metadata": {},
   "source": [
    "### S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"side-50_dens-0.7_pop-0.3_hom-0.3_town-True_RANDOM\"\n",
    "\n",
    "\n",
    "FSI = False\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "folder_distance = \"../results_data/results_data_supplementary/\"+folder+\"/distance_\"+folder\n",
    "folder_gravity = \"../results_data/results_data_supplementary/\"+folder+\"/gravity_\"+folder\n",
    "folder_relevance = \"../results_data/results_data_supplementary/\"+folder+\"/relevance_\"+folder\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder = folder_relevance\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results = pd.concat([results,temp])\n",
    "\n",
    "\n",
    "results[\"model\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results[\"metric\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"metric\"] if \"metric\" in m else 0)\n",
    "results[\"alpha\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"alpha\"] if \"alpha\" in m else 0)\n",
    "\n",
    "    \n",
    "if FSI:\n",
    "    results[\"total_segregation\"] = results[\"fsi\"] \n",
    "\n",
    "group_gravityalfa = results.groupby([\"alpha\"]).agg(mean_step=('Step', np.mean), \n",
    "                                                               mean_seg=('total_segregation', np.mean),\n",
    "                                                               mean_cen_seg=('center_segregation', np.mean),\n",
    "                                                                mean_per_seg=('periphery_segregation', np.mean),\n",
    "                                                              ).reset_index()\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "step_min = min(group_gravityalfa[\"mean_step\"].min(), group_gravityalfa[\"mean_step\"].min()) \n",
    "step_max = max(group_gravityalfa[\"mean_step\"].max(), group_gravityalfa[\"mean_step\"].max()) \n",
    "\n",
    "\n",
    "\n",
    "seg_min = min(group_gravityalfa[\"mean_seg\"].min(), group_gravityalfa[\"mean_seg\"].min()) \n",
    "seg_max = max(group_gravityalfa[\"mean_seg\"].max(), group_gravityalfa[\"mean_seg\"].max()) \n",
    "\n",
    "\n",
    "a1 = alt.Chart(group_gravityalfa).mark_circle(size=75).encode(\n",
    "      x = alt.X('mean_step', scale=alt.Scale(domain=[step_min, step_max]),axis=alt.Axis(title='n')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S')),\n",
    "    color=alt.Color('alpha', scale=alt.Scale(scheme='oranges'), legend=alt.Legend(title=\"α\", titleFontWeight=\"normal\", labelFontSize=16,titleFontSize=20))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return a/(x**b)+c\n",
    "\n",
    "\n",
    "xdata = group_gravityalfa[\"mean_step\"]\n",
    "ydata =  group_gravityalfa[\"mean_seg\"]\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "    \n",
    "    print(\"a1\")\n",
    "    print(\"a/(x**b) +c\")\n",
    "    print(popt)\n",
    "\n",
    "    rega1 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "a2 = alt.Chart(group_gravityalfa).mark_circle(size=75, color=\"black\").encode(\n",
    "      x = alt.X('alpha', scale=alt.Scale(domain=[0, 3]),axis=alt.Axis(title='α')),\n",
    "    y = alt.Y('mean_step', scale=alt.Scale(domain=[step_min, step_max]), axis=alt.Axis(title='n'))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "\n",
    "def func(x,a, b,c):\n",
    "    return (a**(b*x))+c\n",
    "\n",
    "\n",
    "xdata = group_gravityalfa[\"alpha\"]\n",
    "ydata =  group_gravityalfa[\"mean_step\"]\n",
    "\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "    \n",
    "    print(\"a2\")\n",
    "    print(\"(a**(b*x))+c\")\n",
    "    print(popt)\n",
    "\n",
    "    rega2 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "a3 = alt.Chart(group_gravityalfa).mark_circle(size=75, color=\"black\").encode(\n",
    "      x = alt.X('alpha', scale=alt.Scale(domain=[0, 3]),axis=alt.Axis(title='α')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S'))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "def func(x, a, b,c):\n",
    "    return a*x**2+b*x+c\n",
    "\n",
    "\n",
    "try:\n",
    "    xdata = group_gravityalfa[\"alpha\"]\n",
    "    ydata =  group_gravityalfa[\"mean_seg\"]\n",
    "\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "\n",
    "    print(\"a*x**2+b*x+c\")\n",
    "    print(popt)\n",
    "\n",
    "    rega3 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "    \n",
    "\n",
    "alt.hconcat( a1,a2,a3  ).resolve_scale(\n",
    "    color='independent').configure_axis(\n",
    "    gridOpacity=0.5,titleFontWeight=\"normal\", labelFontSize =16, titleFontSize=19, labelAngle=0\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fdc87",
   "metadata": {},
   "source": [
    "### S2 - S9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"side-50_dens-0.7_pop-0.3_hom-0.3_town-True\"\n",
    "\n",
    "import altair as alt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "supplementary = False\n",
    "FSI = False\n",
    "\n",
    "folder_distance = \"../results_data/results_data_main/distance_\"+folder\n",
    "folder_gravity = \"../results_data/results_data_main/gravity_\"+folder\n",
    "folder_relevance = \"../results_data/results_data_main/relevance_\"+folder\n",
    "\n",
    "if supplementary:\n",
    "    folder_distance = \"supplementary/\"+folder+\"/distance_\"+folder\n",
    "    folder_gravity = \"supplementary/\"+folder+\"/gravity_\"+folder\n",
    "    folder_relevance = \"supplementary/\"+folder+\"/relevance_\"+folder\n",
    "    \n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "folder = folder_distance\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results = pd.concat([results,temp])\n",
    "    \n",
    "if FSI:\n",
    "    results[\"total_segregation\"] = results[\"fsi\"] \n",
    "\n",
    "results[\"model\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results[\"beta\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"beta\"] if \"beta\" in m else 0)\n",
    "\n",
    "group_gravity= results.groupby([\"beta\"]).agg(mean_step=('Step', np.mean), mean_seg=(\n",
    "'total_segregation', np.mean)).reset_index()\n",
    "\n",
    "#######################################\n",
    "\n",
    "folder = folder_relevance\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results = pd.concat([results,temp])\n",
    "\n",
    "\n",
    "results[\"model\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results[\"metric\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"metric\"] if \"metric\" in m else 0)\n",
    "results[\"alpha\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"alpha\"] if \"alpha\" in m else 0)\n",
    "\n",
    "    \n",
    "if FSI:\n",
    "    results[\"total_segregation\"] = results[\"fsi\"] \n",
    "\n",
    "group_gravityalfa = results.groupby([\"alpha\"]).agg(mean_step=('Step', np.mean), \n",
    "                                                               mean_seg=('total_segregation', np.mean),\n",
    "                                                               mean_cen_seg=('center_segregation', np.mean),\n",
    "                                                                mean_per_seg=('periphery_segregation', np.mean),\n",
    "                                                              ).reset_index()\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "seg_min = min(group_gravity[\"mean_seg\"].min(), group_gravityalfa[\"mean_seg\"].min()) \n",
    "seg_max = max(group_gravity[\"mean_seg\"].max(), group_gravityalfa[\"mean_seg\"].max()) \n",
    "\n",
    "step_min = min(group_gravity[\"mean_step\"].min(), group_gravityalfa[\"mean_step\"].min()) \n",
    "step_max = max(group_gravity[\"mean_step\"].max(), group_gravityalfa[\"mean_step\"].max()) \n",
    "\n",
    "\n",
    "clas = alt.Chart(group_gravity[group_gravity[\"beta\"]==0]).mark_point(size=100, color='black').encode(\n",
    "      x = alt.X('mean_step', scale=alt.Scale(domain=[step_min, step_max]),axis=alt.Axis(title=\"n\")),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S'))).properties(\n",
    "    width=300,  height=300)\n",
    "\n",
    "text = alt.Chart({'values':[{'x': step_max/2, 'y': (seg_min+seg_max)/2-0.002}]}).mark_text(\n",
    "    text='Original Schelling', angle=0, size=14\n",
    ").encode(x='x:Q', y='y:Q')\n",
    "\n",
    "\n",
    "df = pd.DataFrame({    'x': [step_max/2, group_gravity[group_gravity[\"beta\"]==0][\"mean_step\"].values[0]],\n",
    "                       'y': [(seg_min+seg_max)/2, group_gravity[group_gravity[\"beta\"]==0][\"mean_seg\"].values[0]]})\n",
    "arr = alt.Chart(df).mark_line(color=\"black\").encode(x='x',    y='y',)\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "b1 = alt.Chart(group_gravity).mark_circle(size=75).encode(\n",
    "      x = alt.X('mean_step', scale=alt.Scale(domain=[step_min, step_max]),axis=alt.Axis(title='n')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S')),\n",
    "    color=alt.Color('beta', scale=alt.Scale(scheme='purpleorange'), legend=alt.Legend(title=\"β\",  titleFontWeight=\"normal\", labelFontSize=16,titleFontSize=20))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return a/(x**b)+c\n",
    "\n",
    "xdata = group_gravity[\"mean_step\"]\n",
    "ydata =  group_gravity[\"mean_seg\"]\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "    \n",
    "    print(\"b1\")\n",
    "    print(\"a/(x**b)+c\")\n",
    "    print(popt)\n",
    "\n",
    "    regb1 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, \n",
    "                                      strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "#####################################################\n",
    "\n",
    "b2 = alt.Chart(group_gravity).mark_circle(size=75, color=\"black\").encode(\n",
    "      x = alt.X('beta', scale=alt.Scale(domain=[-5, 5]), axis=alt.Axis(title='β')),\n",
    "    y = alt.Y('mean_step', scale=alt.Scale(domain=[step_min, step_max]), axis=alt.Axis(title='n')),\n",
    "#color=alt.Color('mean_seg', scale=alt.Scale(scheme='redblue'), legend=alt.Legend(title=\"seg\"))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "def func(x, a, b,c):\n",
    "    return (a**(-b*x))+c\n",
    "\n",
    "xdata = group_gravity[\"beta\"]\n",
    "ydata =  group_gravity[\"mean_step\"]\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "    \n",
    "    print(\"b2\")\n",
    "    print(\"a**(-b*x)+c\")\n",
    "    print(popt)\n",
    "\n",
    "    regb2 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "#####################################################\n",
    "\n",
    "b3 = alt.Chart(group_gravity).mark_circle(size=75, color=\"black\").encode(\n",
    "      x = alt.X('beta', scale=alt.Scale(domain=[-5,5]), axis=alt.Axis(title='β')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S')),\n",
    "#color=alt.Color('mean_step', scale=alt.Scale(scheme='redblue'), legend=alt.Legend(title=\"ste\"))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "\n",
    "def func(x, a, b, c, d, k):\n",
    "    return a/(d**(-b*x)+c)+k\n",
    "\n",
    "xdata = group_gravity[\"beta\"]\n",
    "ydata =  group_gravity[\"mean_seg\"]\n",
    "\n",
    "try:\n",
    "\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "\n",
    "    print(\"b3\")\n",
    "    print(\"a/(d**(-b*x)+c)+k\")\n",
    "    print(popt)\n",
    "\n",
    "    regb3 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300)\n",
    "\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "a1 = alt.Chart(group_gravityalfa).mark_circle(size=75).encode(\n",
    "      x = alt.X('mean_step', scale=alt.Scale(domain=[step_min, step_max]),axis=alt.Axis(title='n')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S')),\n",
    "    color=alt.Color('alpha', scale=alt.Scale(scheme='oranges'), legend=alt.Legend(title=\"α\", titleFontWeight=\"normal\", labelFontSize=16,titleFontSize=20))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return a/(x**b)+c\n",
    "\n",
    "\n",
    "xdata = group_gravityalfa[\"mean_step\"]\n",
    "ydata =  group_gravityalfa[\"mean_seg\"]\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "    \n",
    "    print(\"a1\")\n",
    "    print(\"a/(x**b) +c\")\n",
    "    print(popt)\n",
    "\n",
    "    rega1 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "a2 = alt.Chart(group_gravityalfa).mark_circle(size=75, color=\"black\").encode(\n",
    "      x = alt.X('alpha', scale=alt.Scale(domain=[0, 3]),axis=alt.Axis(title='α')),\n",
    "    y = alt.Y('mean_step', scale=alt.Scale(domain=[step_min, step_max]), axis=alt.Axis(title='n'))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "\n",
    "def func(x,a, b,c):\n",
    "    return (a**(b*x))+c\n",
    "\n",
    "\n",
    "xdata = group_gravityalfa[\"alpha\"]\n",
    "ydata =  group_gravityalfa[\"mean_step\"]\n",
    "\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "    \n",
    "    print(\"a2\")\n",
    "    print(\"(a**(b*x))+c\")\n",
    "    print(popt)\n",
    "\n",
    "    rega2 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "a3 = alt.Chart(group_gravityalfa).mark_circle(size=75, color=\"black\").encode(\n",
    "      x = alt.X('alpha', scale=alt.Scale(domain=[0, 3]),axis=alt.Axis(title='α')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S'))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "def func(x, a, b,c):\n",
    "    return a*x**2+b*x+c\n",
    "\n",
    "\n",
    "try:\n",
    "    xdata = group_gravityalfa[\"alpha\"]\n",
    "    ydata =  group_gravityalfa[\"mean_seg\"]\n",
    "\n",
    "    popt, pcov = curve_fit(func, xdata, ydata)\n",
    "    pred = pd.DataFrame()\n",
    "    pred[\"xv\"] = xdata\n",
    "    pred[\"yv\"] = func(xdata, *popt)\n",
    "\n",
    "    print(\"a*x**2+b*x+c\")\n",
    "    print(popt)\n",
    "\n",
    "    rega3 = alt.Chart(pred).mark_line(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x=\"xv\", y=\"yv\").properties(\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "except:\n",
    "    print(\"no fit\")\n",
    "\n",
    "    \n",
    "\n",
    "data = alt.Data(values=[{'x': 'A'}])\n",
    "a = (alt.Chart(data).mark_text(text='a)', size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "b = (alt.Chart(data).mark_text(text='b)', size=20, x=0, y=-20, dx = 0, dy=0))\n",
    "c = (alt.Chart(data).mark_text(text='c)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "d = (alt.Chart(data).mark_text(text='d)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "e = (alt.Chart(data).mark_text(text='e)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "f = (alt.Chart(data).mark_text(text='f)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "g = (alt.Chart(data).mark_text(text='g)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "h = (alt.Chart(data).mark_text(text='h)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clas2 = alt.Chart(group_gravityalfa[group_gravityalfa[\"alpha\"]==0]).mark_point(size=100, color='black').encode(\n",
    "      x = alt.X('mean_step', scale=alt.Scale(domain=[step_min, step_max]),axis=alt.Axis(title='n')),\n",
    "    y = alt.Y('mean_seg', scale=alt.Scale(domain=[seg_min, seg_max]), axis=alt.Axis(title='S'))).properties(\n",
    "    width=300,  height=300)\n",
    "\n",
    "text2 = alt.Chart({'values':[{'x': step_max/2, 'y': (seg_min+seg_max)/2-0.002}]}).mark_text(\n",
    "    text='Original Schelling', angle=0, size=14\n",
    ").encode(x='x:Q', y='y:Q')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({    'x': [step_max/2, group_gravityalfa[group_gravityalfa[\"alpha\"]==0][\"mean_step\"].values[0]],\n",
    "                       'y': [(seg_min+seg_max)/2, group_gravityalfa[group_gravityalfa[\"alpha\"]==0][\"mean_seg\"].values[0]]})\n",
    "arr2 = alt.Chart(df).mark_line(color=\"black\").encode(x='x',    y='y',)\n",
    "\n",
    "\n",
    "import altair as alt\n",
    " \n",
    "folder = folder_gravity\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results = pd.concat([results,temp])\n",
    "\n",
    "\n",
    "results[\"model\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results[\"metric\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"metric\"] if \"metric\" in m else 0)\n",
    "results[\"beta\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"beta\"] if \"beta\" in m else 0)\n",
    "results[\"alpha\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"alpha\"] if \"alpha\" in m else 0)\n",
    "\n",
    "    \n",
    "if FSI:\n",
    "    results[\"total_segregation\"] = results[\"fsi\"] \n",
    "    \n",
    "\n",
    "group_gravityalfabeta = results.groupby([\"alpha\",\"beta\"]).agg(mean_step=('Step', np.mean), \n",
    "                                                               mean_seg=('total_segregation', np.mean),\n",
    "                                                               mean_cen_seg=('center_segregation', np.mean),\n",
    "                                                                mean_per_seg=('periphery_segregation', np.mean),\n",
    "                                                              ).reset_index()\n",
    "\n",
    "\n",
    "#group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#]\n",
    "group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"] == group_gravityalfabeta[\"alpha\"].apply(lambda x: int(x))]\n",
    "\n",
    "\n",
    "\n",
    "heatmap1 = alt.Chart(group_gravityalfabeta).mark_rect().encode(\n",
    "    alt.X('beta:O', title=\"β\"),\n",
    "    alt.Y('alpha:O', title=\"α\", scale=alt.Scale(reverse=True)),\n",
    "    \n",
    "    color=alt.Color('mean_seg:Q',\n",
    "        scale=alt.Scale(scheme='greens'),\n",
    "        legend=alt.Legend(title=\"S\", titleFontWeight=\"normal\",  labelFontSize=16,titleFontSize=20),\n",
    "    )).properties(\n",
    "    width=450,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "heatmap2 = alt.Chart(group_gravityalfabeta).mark_rect().encode(\n",
    "    alt.X('beta:O', title=\"β\"),\n",
    "    alt.Y('alpha:O', title=\"α\", scale=alt.Scale(reverse=True)),\n",
    "    \n",
    "    color=alt.Color('mean_step:Q',\n",
    "        scale=alt.Scale(scheme='greens'),\n",
    "        legend=alt.Legend(title=\"n\", titleFontWeight=\"normal\",  labelFontSize=16,titleFontSize=20),\n",
    "    )).properties(\n",
    "    width=450,\n",
    "    height=300)\n",
    "\n",
    "line  = alt.Chart(pd.DataFrame({'x': [0]})).mark_rule(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x='x')\n",
    "\n",
    "try:\n",
    "    B1 = (b1 + regb1 + clas + text + arr+a) \n",
    "except:\n",
    "    B1 = (b1  + clas + text + arr+a) \n",
    "    \n",
    "try:\n",
    "    B2 = (b2+regb2+b+line)\n",
    "except:\n",
    "    B2 = (b2+b+line)\n",
    "    a\n",
    "try:\n",
    "    B3 = (b3+regb3+c+line)\n",
    "except:\n",
    "    B3 = (b3+c+line)\n",
    "    \n",
    "try:\n",
    "    A1 = (a1 + rega1 + clas2 + text2 + arr2 +d)\n",
    "except:\n",
    "    A1 = (a1  + clas2 + text2 + arr2 +d)\n",
    "    \n",
    "try:\n",
    "    A2 = (a2+rega2+e)\n",
    "except:\n",
    "    A2 = (a2+e)\n",
    "    \n",
    "try:\n",
    "    A3 = (a3+rega3+f)\n",
    "except:\n",
    "    A3 = (a3+f)\n",
    "    \n",
    "chart = alt.vconcat(\n",
    "    \n",
    "    alt.hconcat(  B1, B2, B3   ).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(A1, A2 ,A3).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(heatmap1+g, heatmap2+h ).resolve_scale(\n",
    "    color='independent') \n",
    "    \n",
    ").resolve_scale(\n",
    "    color='independent').configure_axis(\n",
    "    gridOpacity=0.5,titleFontWeight=\"normal\", labelFontSize =16, titleFontSize=19, labelAngle=0\n",
    "    \n",
    "    )\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c396652",
   "metadata": {},
   "source": [
    "### S10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "folder = \"side-50_dens-0.7_pop-0.3_hom-0.3_town-True\"\n",
    "\n",
    "\n",
    "folder_distance = \"../results_data/results_data_main/distance_\"+folder\n",
    "folder_relevance = \"../results_data/results_data_main/relevance_\"+folder\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "folder = folder_distance\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results_beta = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results_beta = pd.concat([results_beta,temp])\n",
    "    \n",
    "\n",
    "\n",
    "results_beta[\"model\"] = results_beta[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results_beta[\"beta\"] = results_beta[\"mobility\"].apply(lambda m: eval(m)[\"beta\"] if \"beta\" in m else 0)\n",
    "\n",
    "group_gravity= results_beta.groupby([\"beta\"]).agg(mean_step=('Step', np.mean), mean_seg=(\n",
    "'total_segregation', np.mean)).reset_index()\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "folder = folder_relevance\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results_alpha = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results_alpha = pd.concat([results_alpha,temp])\n",
    "\n",
    "\n",
    "results_alpha[\"model\"] = results_alpha[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results_alpha[\"alpha\"] = results_alpha[\"mobility\"].apply(lambda m: eval(m)[\"alpha\"] if \"alpha\" in m else 0)\n",
    "\n",
    "    \n",
    "group_gravityalfa= results_alpha.groupby([\"alpha\"]).agg(mean_step=('Step', np.mean), mean_seg=(\n",
    "'total_segregation', np.mean)).reset_index()\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "seg_min = min(group_gravity[\"mean_seg\"].min(), group_gravityalfa[\"mean_seg\"].min()) \n",
    "seg_max = max(group_gravity[\"mean_seg\"].max(), group_gravityalfa[\"mean_seg\"].max()) \n",
    "\n",
    "step_min = min(group_gravity[\"mean_step\"].min(), group_gravityalfa[\"mean_step\"].min()) \n",
    "step_max = max(group_gravity[\"mean_step\"].max(), group_gravityalfa[\"mean_step\"].max()) \n",
    "\n",
    "\n",
    "b2 = alt.Chart(results_beta).mark_boxplot(size=3, color=\"black\").encode(\n",
    "      x = alt.X('beta', scale=alt.Scale(domain=[-4,4]), axis=alt.Axis(title='β')),\n",
    "    y = alt.Y('Step', scale=alt.Scale(domain=[0, 550]), axis=alt.Axis(title='n')),\n",
    "#color=alt.Color('mean_step', scale=alt.Scale(scheme='redblue'), legend=alt.Legend(title=\"ste\"))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "\n",
    "b3 = alt.Chart(results_beta).mark_boxplot(size=3, color=\"black\").encode(\n",
    "      x = alt.X('beta', scale=alt.Scale(domain=[-4,4]), axis=alt.Axis(title='β')),\n",
    "    y = alt.Y('total_segregation', scale=alt.Scale(domain=[seg_min-0.05, seg_max+0.05]), axis=alt.Axis(title='S')),\n",
    "#color=alt.Color('mean_step', scale=alt.Scale(scheme='redblue'), legend=alt.Legend(title=\"ste\"))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "a2 = alt.Chart(results_alpha).mark_boxplot(size=3, color=\"black\").encode(\n",
    "      x = alt.X('alpha', scale=alt.Scale(domain=[0,3]), axis=alt.Axis(title='α')),\n",
    "    y = alt.Y('Step', scale=alt.Scale(domain=[0, 550]), axis=alt.Axis(title='n')),\n",
    "#color=alt.Color('mean_step', scale=alt.Scale(scheme='redblue'), legend=alt.Legend(title=\"ste\"))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "\n",
    "a3 = alt.Chart(results_alpha).mark_boxplot(size=3, color=\"black\").encode(\n",
    "      x = alt.X('alpha', scale=alt.Scale(domain=[0,3]), axis=alt.Axis(title='α')),\n",
    "    y = alt.Y('total_segregation', scale=alt.Scale(domain=[seg_min-0.05, seg_max+0.05]), axis=alt.Axis(title='S')),\n",
    "#color=alt.Color('mean_step', scale=alt.Scale(scheme='redblue'), legend=alt.Legend(title=\"ste\"))\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "data = alt.Data(values=[{'x': 'A'}])\n",
    "a = (alt.Chart(data).mark_text(text='a)', size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "b = (alt.Chart(data).mark_text(text='b)', size=20, x=0, y=-20, dx = 0, dy=0))\n",
    "c = (alt.Chart(data).mark_text(text='c)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "d = (alt.Chart(data).mark_text(text='d)',  size=20, x=0, y=-20, dx = 0, dy= 0))\n",
    "\n",
    "\n",
    "line  = alt.Chart(pd.DataFrame({'x': [0]})).mark_rule(color=\"grey\", opacity=1, width=2, strokeDash=[10,5]).encode(x='x')\n",
    "\n",
    "\n",
    "A = (b2+a+line)\n",
    "B = (b3+b+line)\n",
    "C =(a2+c)\n",
    "D = (a3+d)\n",
    "\n",
    "chart = alt.vconcat(\n",
    "    \n",
    "    alt.hconcat(  A,B   ).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(C,D).resolve_scale(\n",
    "    color='independent') \n",
    "    \n",
    ").resolve_scale(\n",
    "    color='independent').configure_axis(\n",
    "    gridOpacity=0.5,titleFontWeight=\"normal\", labelFontSize =16, titleFontSize=19, labelAngle=0\n",
    "    \n",
    "    )\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85942caa",
   "metadata": {},
   "source": [
    "### S11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b744ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [ -5, -3, -1, 0,  1 , 3, 5]\n",
    "alphas = [0  ,0.5 ,1,1.5, 2, 2.5,3]\n",
    "\n",
    "\n",
    "betahists_S = []\n",
    "alphahists_S = []\n",
    "\n",
    "\n",
    "betahists_n = []\n",
    "alphahists_n = []\n",
    "\n",
    "for beta in betas:\n",
    "    \n",
    "    source = results_beta[results_beta[\"beta\"]== beta]\n",
    "    chart = alt.Chart(source).mark_bar().encode(\n",
    "    alt.X(\"total_segregation:Q\", bin=True, title=\"S\"),\n",
    "    alt.Y('count()', title=\"β=\"+str(beta)))\n",
    "    \n",
    "    betahists_S.append(chart)\n",
    "    \n",
    "    source = results_beta[results_beta[\"beta\"]== beta]\n",
    "    chart = alt.Chart(source).mark_bar().encode(\n",
    "    alt.X(\"Step:Q\", bin=True, title=\"n\"),\n",
    "    alt.Y('count()', title=\"β=\"+str(beta)))\n",
    "    \n",
    "    betahists_n.append(chart)\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    source = results_alpha[results_alpha[\"alpha\"]== alpha]\n",
    "    chart = alt.Chart(source).mark_bar().encode(\n",
    "    alt.X(\"total_segregation:Q\", bin=True, title=\"S\"),\n",
    "    alt.Y('count()', title=\"α=\"+str(alpha)))\n",
    "    \n",
    "    alphahists_S.append(chart)\n",
    "\n",
    "    source = results_alpha[results_alpha[\"alpha\"]== alpha]\n",
    "    chart = alt.Chart(source).mark_bar().encode(\n",
    "    alt.X(\"Step:Q\", bin=True, title=\"n\"),\n",
    "    alt.Y('count()', title=\"α=\"+str(alpha)))    \n",
    "    alphahists_n.append(chart)\n",
    "    \n",
    "\n",
    "\n",
    "chart = alt.vconcat(\n",
    "    \n",
    "    alt.hconcat(  betahists_S[0],alphahists_S[0], betahists_n[0],alphahists_n[0]).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(  betahists_S[1],alphahists_S[1], betahists_n[1],alphahists_n[1]).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(  betahists_S[2],alphahists_S[2], betahists_n[2],alphahists_n[2]).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(  betahists_S[3],alphahists_S[3], betahists_n[3],alphahists_n[3]).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(  betahists_S[4],alphahists_S[4], betahists_n[4],alphahists_n[4]).resolve_scale(\n",
    "    color='independent') &\n",
    "    \n",
    "    alt.hconcat(  betahists_S[5],alphahists_S[5], betahists_n[5],alphahists_n[5]).resolve_scale(\n",
    "    color='independent')  &\n",
    "    \n",
    "    alt.hconcat(  betahists_S[6],alphahists_S[6], betahists_n[6],alphahists_n[6]).resolve_scale(\n",
    "    color='independent') \n",
    "    \n",
    "    \n",
    ").resolve_scale(\n",
    "    color='independent').configure_axis(\n",
    "    gridOpacity=0.5,titleFontWeight=\"normal\", labelFontSize =16, titleFontSize=19, labelAngle=0\n",
    "    \n",
    "    )\n",
    "\n",
    "chart\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9ce3a",
   "metadata": {},
   "source": [
    "### S12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b209ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder = \"../results_data/results_data_main/gravity_side-50_dens-0.7_pop-0.3_hom-0.3_town-True/\"\n",
    "\n",
    "\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results = pd.concat([results,temp])\n",
    "\n",
    "\n",
    "results[\"model\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results[\"metric\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"metric\"] if \"metric\" in m else 0)\n",
    "results[\"beta\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"beta\"] if \"beta\" in m else 0)\n",
    "results[\"alpha\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"alpha\"] if \"alpha\" in m else 0)\n",
    "\n",
    "    \n",
    "    \n",
    "group_gravityalfabeta = results.groupby([\"alpha\",\"beta\"]).agg(mean_step=('Step', np.mean), \n",
    "                                                               mean_seg=('total_segregation', np.mean),\n",
    "                                                               mean_cen_seg=('center_segregation', np.mean),\n",
    "                                                                mean_per_seg=('periphery_segregation', np.mean),\n",
    "                                                              ).reset_index()\n",
    "\n",
    "\n",
    "#group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#]\n",
    "group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"] == group_gravityalfabeta[\"alpha\"].apply(lambda x: int(x))]\n",
    "\n",
    "group_gravityalfabeta.rename(columns={\"mean_cen_seg\": \"center\",\n",
    "                                     \"mean_per_seg\": \"periphery\"}, inplace=True)\n",
    "\n",
    "\n",
    "group_gravityalfabeta[\"seg_diff\"] = group_gravityalfabeta[\"periphery\"] - group_gravityalfabeta[\"center\"]\n",
    "\n",
    "df0 = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]==0][[\"beta\",\"center\",\"seg_diff\"]]\n",
    "\n",
    "\n",
    "ch0 = alt.Chart(df0).mark_bar().encode(\n",
    "    alt.X('beta:N', axis=alt.Axis(title=\"β\")),\n",
    "    alt.Y('seg_diff:Q', axis=alt.Axis(title='ΔS'), scale=alt.Scale(domain=[0,.1])),\n",
    "   ).properties(title=\"α=0\")\n",
    "\n",
    "df1 = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]==1][[\"beta\",\"center\",\"seg_diff\"]]\n",
    "\n",
    "ch1 =  alt.Chart(df1).mark_bar().encode(\n",
    "    alt.X('beta:N', axis=alt.Axis(title=\"β\")),\n",
    "    alt.Y('seg_diff:Q', axis=alt.Axis(title=''), scale=alt.Scale(domain=[0,.1])),\n",
    "  ).properties(title=\"α=1\")\n",
    "\n",
    "df2 = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]==2][[\"beta\",\"center\",\"seg_diff\"]]\n",
    "\n",
    "\n",
    "ch2 = alt.Chart(df2).mark_bar().encode(\n",
    "    alt.X('beta:N', axis=alt.Axis(title=\"β\")),\n",
    "    alt.Y('seg_diff:Q', axis=alt.Axis(title=''), scale=alt.Scale(domain=[0,.1])),\n",
    "    ).properties(title=\"α=2\")\n",
    "\n",
    "df3 = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]==3][[\"beta\",\"center\",\"seg_diff\"]]\n",
    "\n",
    "\n",
    "ch3 =  alt.Chart(df3).mark_bar().encode(\n",
    "    alt.X('beta:N', axis=alt.Axis(title=\"β\")),\n",
    "    alt.Y('seg_diff:Q', axis=alt.Axis(title=''), scale=alt.Scale(domain=[0,.1])),\n",
    "    ).properties(title=\"α=3\")\n",
    "\n",
    "\n",
    "\n",
    "alt.hconcat( ch0,ch1,ch2,ch3  ).configure_axis(\n",
    "    gridOpacity=0.5,titleFontWeight=\"normal\",  labelFontSize =16, titleFontSize=19, labelAngle=0\n",
    "    \n",
    "    ).configure_mark(\n",
    "    color='#fcc40f'\n",
    ").configure_title(fontSize=20, fontWeight=\"normal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbb547",
   "metadata": {},
   "source": [
    "### S13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667612d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder = \"../results_data/results_data_supplementary/gravity_extended_side-50_dens-0.7_pop-0.3_hom-0.3_town-True/\"\n",
    "\n",
    "\n",
    "csv_list = os.listdir(folder)\n",
    "results = pd.read_csv(folder+\"/\"+csv_list[0])\n",
    "\n",
    "for csv in csv_list[1:]:\n",
    "    temp = pd.read_csv(folder+\"/\"+csv)\n",
    "    results = pd.concat([results,temp])\n",
    "\n",
    "\n",
    "results[\"model\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"model\"])\n",
    "results[\"metric\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"metric\"] if \"metric\" in m else 0)\n",
    "results[\"beta\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"beta\"] if \"beta\" in m else 0)\n",
    "results[\"alpha\"] = results[\"mobility\"].apply(lambda m: eval(m)[\"alpha\"] if \"alpha\" in m else 0)\n",
    "\n",
    "    \n",
    "    \n",
    "group_gravityalfabeta = results.groupby([\"alpha\",\"beta\"]).agg(mean_step=('Step', np.mean), \n",
    "                                                               mean_seg=('total_segregation', np.mean),\n",
    "                                                               mean_cen_seg=('center_segregation', np.mean),\n",
    "                                                                mean_per_seg=('periphery_segregation', np.mean),\n",
    "                                                              ).reset_index()\n",
    "\n",
    "\n",
    "#group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#]\n",
    "group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"] == group_gravityalfabeta[\"alpha\"].apply(lambda x: int(x))]\n",
    "\n",
    "\n",
    "\n",
    "#group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]<=2#]\n",
    "group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"] == group_gravityalfabeta[\"alpha\"].apply(lambda x: int(x))]\n",
    "\n",
    "\n",
    "group_gravityalfabeta = group_gravityalfabeta[group_gravityalfabeta[\"alpha\"]>=0]\n",
    "\n",
    "heatmap1 = alt.Chart(group_gravityalfabeta).mark_rect().encode(\n",
    "    alt.X('beta:O', title=\"β\"),\n",
    "    alt.Y('alpha:O', title=\"α\", scale=alt.Scale(reverse=True)),\n",
    "    \n",
    "    color=alt.Color('mean_seg:Q',\n",
    "        scale=alt.Scale(scheme='greens'),\n",
    "        legend=alt.Legend(title=\"S\", titleFontWeight=\"normal\",  labelFontSize=16,titleFontSize=20),\n",
    "    )).properties(\n",
    "    width=450,\n",
    "    height=300)\n",
    "\n",
    "\n",
    "heatmap2 = alt.Chart(group_gravityalfabeta).mark_rect().encode(\n",
    "    alt.X('beta:O', title=\"β\"),\n",
    "    alt.Y('alpha:O', title=\"α\", scale=alt.Scale(reverse=True)),\n",
    "    \n",
    "    color=alt.Color('mean_step:Q',\n",
    "        scale=alt.Scale(scheme='greens'),\n",
    "        legend=alt.Legend(title=\"n\", titleFontWeight=\"normal\",  labelFontSize=16,titleFontSize=20),\n",
    "    )).properties(\n",
    "    width=450,\n",
    "    height=300)\n",
    "\n",
    "alt.hconcat(heatmap1 , heatmap2).resolve_scale(\n",
    "    color='independent').configure_axis(\n",
    "    gridOpacity=0.5,titleFontWeight=\"normal\", labelFontSize =16, titleFontSize=19, labelAngle=0\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab4863",
   "metadata": {},
   "source": [
    "### S14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.schellingmob import SchellingAgent, SchellingModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "side = 50\n",
    "\n",
    "city = SchellingModel(side = side, density=.7, seed=1,\n",
    "                              mobility={\"model\":\"gravity\", \"alpha\":3, \"beta\":-3},\n",
    "                              agents_report=True,\n",
    "                              town=True)\n",
    "while city.running and city.schedule.steps <= 500:\n",
    "        city.step()\n",
    "        \n",
    "\n",
    "        \n",
    "agent_df = city.datacollector.get_agent_vars_dataframe().reset_index()\n",
    "\n",
    "unhappy_df = agent_df[agent_df[\"happy\"]==False]\n",
    "unhappy_df = unhappy_df.groupby(\"AgentID\").agg({'Step': 'count', 'type':\"mean\"}).reset_index()\n",
    "unhappy_df[\"type\"] = unhappy_df[\"type\"].apply(lambda x : \"min\" if x==1 else \"maj\")\n",
    "unhappy_df = unhappy_df[unhappy_df[\"Step\"]>200]\n",
    "outliers = list(unhappy_df[\"AgentID\"])\n",
    "\n",
    "model_df = city.datacollector.get_model_vars_dataframe()\n",
    "pct_change_censeg = model_df[\"center_segregation\"].pct_change(periods=5)\n",
    "\n",
    "step_treshold = pct_change_censeg.lt(0.02).idxmax()\n",
    "print(step_treshold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(model_df[\"center_segregation\"])\n",
    "plt.axvline(x = step_treshold, color = 'r')\n",
    "#plt.savefig('tippingpoint.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change_censeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model_df[\"center_segregation\"])\n",
    "plt.xlabel(\"Steps\", size=15)\n",
    "plt.ylabel(\"Segregation of center\", size=15)\n",
    "plt.axvline(x = step_treshold, color = 'r')\n",
    "plt.savefig('tippingpoint.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee9770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2aea86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357ee35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211ba52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ffa743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
